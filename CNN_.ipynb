{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMukdiz0D+w25fKmhsI7O7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amit-Padye/CNN/blob/main/CNN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEVpF1rjt3yH",
        "outputId": "566c3c08-5e53-4d5a-afb6-1660f579902b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting mnist\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ]
        }
      ],
      "source": [
        " pip install tensorflow numpy mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mnist\n",
        "from tensorflow import keras\n",
        "\n",
        "# The first time you run this might be a bit slow, since the\n",
        "# mnist package has to download and cache the data.\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "\n",
        "print(train_images.shape) # (60000, 28, 28)\n",
        "print(train_labels.shape) # (60000,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA91z3Z5v46w",
        "outputId": "5c677db0-bc17-4ace-f976-e29238f307e1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mnist\n",
        "\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n",
        "\n",
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "\n"
      ],
      "metadata": {
        "id": "UIIQ2WBKwP_F"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhyQeim119Dh",
        "outputId": "bed363bf-4f64-44f1-c31e-824da05eb99f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        ...,\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]],\n",
              "\n",
              "       [[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        ...,\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]],\n",
              "\n",
              "       [[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        ...,\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        ...,\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]],\n",
              "\n",
              "       [[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        ...,\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]],\n",
              "\n",
              "       [[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        ...,\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
              "        [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the images.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)\n",
        "\n",
        "print(train_images.shape) # (60000, 28, 28, 1)\n",
        "print(test_images.shape)  # (10000, 28, 28, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGHJk9Ym140X",
        "outputId": "dd11b344-459e-4092-cec4-c9b0ca278f81"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# WIP\n",
        "model = Sequential([\n",
        "  # layers...\n",
        "])"
      ],
      "metadata": {
        "id": "JCSgHu9N1vty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxYOFaxW1X_i",
        "outputId": "ce5ddff6-e77d-45f0-c03d-18517614c8c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "XHYRhPi55UM3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "x__aoRIV5WHG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mnist\n",
        "\n",
        "train_labels = mnist.train_labels()\n",
        "print(train_labels[0]) # 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oR-4l_15eWI",
        "outputId": "510fbad8-64e7-4dc7-bde4-11d2474a0cfe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIJgJt6C6A5o",
        "outputId": "d91a4bc7-5cde-4a2c-f8e0-3faa3edc73dc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3500 - accuracy: 0.8985 - val_loss: 0.2125 - val_accuracy: 0.9368\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1922 - accuracy: 0.9439 - val_loss: 0.1502 - val_accuracy: 0.9550\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1416 - accuracy: 0.9593 - val_loss: 0.1255 - val_accuracy: 0.9628\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45f8e50c90>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n",
        "\n",
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "\n",
        "# Reshape the images.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)\n",
        "\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "\n",
        "# Build the model.\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train the model.\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeRhZFqt6DiI",
        "outputId": "acef36c4-3c83-49dc-fb67-6b34d2b18e50"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 21s 4ms/step - loss: 0.3579 - accuracy: 0.8976 - val_loss: 0.2024 - val_accuracy: 0.9432\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1744 - accuracy: 0.9504 - val_loss: 0.1411 - val_accuracy: 0.9594\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1274 - accuracy: 0.9639 - val_loss: 0.1171 - val_accuracy: 0.9633\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f066013f5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('cnn.h5')"
      ],
      "metadata": {
        "id": "_nbRm0Gd6pYa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model's saved weights.\n",
        "model.load_weights('cnn.h5')"
      ],
      "metadata": {
        "id": "abqAiKMz_JO3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1iojUor_jd9",
        "outputId": "1f51eee0-1744-43f1-ba70-854eab0478cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "UTEYFAmV_n0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Network Depth\n",
        "What happens if we add or remove Convolutional layers? How does that affect training and/or the modelâ€™s final performance?"
      ],
      "metadata": {
        "id": "4vO_3G3jAwZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  Conv2D(num_filters, filter_size),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "FfKpLKsj_nvz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dropout"
      ],
      "metadata": {
        "id": "gk-yuwIfBEeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Dropout(0.5),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "D9P-xQyoA30Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fully-connected Layers"
      ],
      "metadata": {
        "id": "SrtPyE1jBIN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n"
      ],
      "metadata": {
        "id": "u7nHiFDRA3u5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These can be changed, too!\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "\n",
        "model = Sequential([\n",
        "  # See https://keras.io/layers/convolutional/#conv2d for more info.\n",
        "  Conv2D(\n",
        "    num_filters,\n",
        "    filter_size,\n",
        "    input_shape=(28, 28, 1),\n",
        "    strides=2,\n",
        "    padding='same',\n",
        "    activation='relu',\n",
        "  ),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "x2eGqX5rBNu-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zRHLCIDjBNqB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}